---
title: "Practica 1_nba"
author: "Alvaro Muñoz Jimenez"
date: "10/10/2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
#library(tidyverse)
#library(readr)
#library(dplyr)
#library(TeachingDemos)
#library(nortest)
#library(car)
#library(MASS)
#library(leaps)
#library(gvlma)
#ibrary(ISLR)
#library(tinytex)


#El objetivo del ejercicio es crear un modelo para estimar el salario de los jugadores de #la nba en funcion de las estadisticas y habilidades de cada jugador.

#En primer lugar importo el dataset correspondiente a los datos de "nba".

```{r}
nba<-read.csv("C:/Users/alvar/Desktop/CUNEF/PREDICCIÓN/nba.csv")

```

#El siguiente paso es suprimir los NAs pertenecientes al objeto nba.

```{r}
nba <- unique(nba)

nba <- na.omit(nba)
```

#Cambio el nombre de las variables.

```{r}
nba<-rename(nba,minutes.played = "MP")
nba<-rename(nba, team= "Tm")
nba<-rename(nba, games= "G")
nba<-rename(nba, efficiency= "PER")
nba<-rename(nba, success= "TS.")
nba<-rename(nba, triple.try= "X3PAr")
nba<-rename(nba, free.try= "FTr")
nba<-rename(nba, rebound.attack= "ORB.")
nba<-rename(nba, rebound.deffence= "DRB.")
nba<-rename(nba, total.rebounds= "TRB.")
nba<-rename(nba, assistance= "AST.")
nba<-rename(nba, stealing= "STL.")
nba<-rename(nba, blocking= "BLK.")
nba<-rename(nba, turnover.percentage= "TOV.")
nba<-rename(nba,  usage.percentage= "USG.")
nba<-rename(nba, good.attack= "OWS")
nba<-rename(nba,good.defence= "DWS")
nba<-rename(nba, total.good= "WS")
nba<-rename(nba, win.shares.per.48= "WS.48")
nba<-rename(nba, puntos.ofensivosVSmedia= "OBPM")
nba<-rename(nba, puntos.defensivosVSmedia= "DBPM")
nba<-rename(nba, puntosVSmedia= "BPM")
nba<-rename(nba, contribution= "VORP")
```

#Creamos el objeto regres01 para estudiar el modelo de regresión y ver la relacion 
#que hay entre la variable dependiente "Salary" y las variables explicativas de la 
#base de datos.

#No se incluyen  las variables equipo, nombre del jugador y pais.


```{r}
vY=nba$Salary
View(vY)

mX=cbind(1,nba[,2:28])
View(mX)

head(vY)
head.matrix(mX)

regres01<-lm(Salary~NBA_DraftNumber + Age + games + minutes.played + efficiency + success 
             + triple.try + free.try + rebound.attack +  rebound.deffence + total.rebounds + assistance + stealing + blocking
             + turnover.percentage + usage.percentage + good.attack + good.defence +total.good + win.shares.per.48
             + puntos.ofensivosVSmedia + puntos.defensivosVSmedia + puntosVSmedia + contribution, data=nba)

summary(regres01)

```

#Utilizo el Modelo  Backward Stepwise y de manera iterativa se van eliminando una a una
#las variables menos útiles.

```{r}
stepAIC(regres01, direction="backward")
```

#Procedo a crear el segundo modelo en función de las variables que menor AIC poseen.

#En este caso eligo el modelo AIC=14923.2.

```{r}
regres02<-lm (Salary ~ NBA_DraftNumber + Age + games + minutes.played + efficiency + 
  triple.try + rebound.attack + total.rebounds + usage.percentage + 
  total.good + puntos.ofensivosVSmedia, data=nba)

summary(regres02)

```

#Para detectar la multicolinealidad utilizo el Factor de Inflación de Varianza (VIF).

```{r}
vif(regres02)

sqrt(vif(regres02)) > 2
```

#Cuando la raiz cuadrada de VIF>2 se considera que hay problemas de multicolinealidad.

#Suprimo las variables que dan problemas y creo un nuevo modelo de regresion.

```{r}
regres03<-lm (Salary ~ NBA_DraftNumber + Age + minutes.played + efficiency + 
                triple.try + rebound.attack + total.rebounds + usage.percentage + 
                total.good + puntos.ofensivosVSmedia, data=nba)

summary(regres03)

vif(regres03)

sqrt(vif(regres03)) > 2


regres04<-lm (Salary ~ NBA_DraftNumber + Age + minutes.played +  
                triple.try + rebound.attack + total.rebounds + usage.percentage + 
                total.good + puntos.ofensivosVSmedia, data=nba)

summary(regres04)

vif(regres04)

sqrt(vif(regres04)) > 2
```


#De esta manera he conseguido eliminar la multicolinealidad. 

#Comparo el modelo inicial "regres01" con el nuevo modelo obtenido "regres04".

```{r}
BIC(regres01,regres04)
```


#Observo que el modelo regres04 es mejor ya que tiene menor BIC.  

#Compruebo la Normalidad para comprobar si se verifica la hipótesis de normalidad 
#necesaria para que el resultado de de esta prediccion sea fiable.

```{r}
qqPlot(regres04, labels=row.names(nba), id.method="identify",
       simulate=TRUE, main="Q-Q Plot")
```

#Contrastamos todas las hipótesis del modelo mediante el test de Peña de Validacion Global.

```{r}
validacion_global <- gvlma(regres04)
summary(validacion_global)

gvlma(x = regres04)

```

#Realizamos la prediccion de un jugador al azar.

```{r}
predict.lm(regres04, data.frame(NBA_DraftNumber=7, Age=29, minutes.played=1631,  
                                 triple.try=0.58,  rebound.attack=2.7, total.rebounds=8.9, 
                                 usage.percentage=31, 
                                 total.good=9.2, puntos.ofensivosVSmedia=9.8 ))

```

#Realizamos un Cross Validation para dividir los datos del modelo predictivo  en nuevos #conjuntos de datos, que son el conjunto de entrenamiento  del modelo y el de
#validacion el modelo


```{r}
set.seed(6)
nbanum<-nrow(nba)
```


```{r}
training<-sample(nbanum, nbanum/2)

regres.training <- lm(Salary~(NBA_DraftNumber + Age + minutes.played +  
                           triple.try + rebound.attack + total.rebounds + usage.percentage + 
                           total.good + puntos.ofensivosVSmedia), nba , subset =training )
```

```{r}
attach(nba)
```

```{r}
mean((Salary-predict(regres.training, Auto))[-training ]^2)
sqrt(mean((Salary-predict(regres.training, Auto))[-training ]^2))
```

#Por último, he obtenido el resultado de error que da mi modelo de prediccion.